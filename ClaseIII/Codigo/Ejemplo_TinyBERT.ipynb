{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo básico utilizando el modelo TinyBERT de Huawei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens de la oración: ['i', 'absolutely', 'love', 'this', 'product', '!', 'it', 'works', 'wonderful', '##ly', '.']\n",
      "Comentario: I absolutely love this product! It works wonderfully. -> Sentimiento: Positivo (Índice de clase: 1)\n",
      "Tokens de la oración: ['i', \"'\", 'm', 'not', 'satisfied', 'with', 'the', 'service', ';', 'it', \"'\", 's', 'too', 'slow', '.']\n",
      "Comentario: I'm not satisfied with the service; it's too slow. -> Sentimiento: Positivo (Índice de clase: 1)\n",
      "Tokens de la oración: ['excellent', 'quality', ';', 'i', 'would', 'recommend', 'it', 'to', 'everyone', '.']\n",
      "Comentario: Excellent quality; I would recommend it to everyone. -> Sentimiento: Positivo (Índice de clase: 1)\n",
      "Tokens de la oración: ['terrible', 'experience', ';', 'i', 'will', 'never', 'buy', 'here', 'again', '.']\n",
      "Comentario: Terrible experience; I will never buy here again. -> Sentimiento: Negativo (Índice de clase: 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77ed091fe484e6ebe4a9fb8ec4645e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/62.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import warnings\n",
    "import logging\n",
    "# Ignorar advertencias\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Ajustar el nivel de logging para Transformers\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Cargar el tokenizer y el modelo TinyBERT de Huawei\n",
    "model_name = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Función para predecir el sentimiento\n",
    "def predict_sentiment(text):\n",
    "    # Tokenización y preparación de los datos\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "    # # Mostrar tokens\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    print(f\"Tokens de la oración: {tokens}\")\n",
    "    # Predicción\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Obtener los logits y la clase con mayor probabilidad\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Interpretar el resultado\n",
    "    sentiment = \"Positivo\" if predicted_class == 1 else \"Negativo\"\n",
    "    return sentiment, predicted_class\n",
    "\n",
    "# Ejemplo de comentarios\n",
    "comments = [\n",
    "    \"I absolutely love this product! It works wonderfully.\",\n",
    "    \"I'm not satisfied with the service; it's too slow.\",\n",
    "    \"Excellent quality; I would recommend it to everyone.\",\n",
    "    \"Terrible experience; I will never buy here again.\"\n",
    "]\n",
    "\n",
    "# Predecir el sentimiento de cada comentario\n",
    "for comment in comments:\n",
    "    sentiment, class_index = predict_sentiment(comment)\n",
    "    print(f\"Comentario: {comment} -> Sentimiento: {sentiment} (Índice de clase: {class_index})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detalles del Modelo:\n",
      "---------------------\n",
      "Nombre del Modelo: huawei-noah/TinyBERT_General_4L_312D\n",
      "Número de capas: 4\n",
      "Tamaño del vector embedding: 312\n",
      "Tamaño del vocabulario del modelo: 30522\n",
      "Número de parámetros del modelo: 14350874\n",
      "Número de parámetros entrenables: 14350874\n"
     ]
    }
   ],
   "source": [
    "# Imprimir detalles del modelo\n",
    "print(\"Detalles del Modelo:\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Nombre del Modelo: {model_name}\")\n",
    "print(f\"Número de capas: {model.bert.encoder.layer.__len__()}\")\n",
    "print(f\"Tamaño del vector embedding: {model.bert.embeddings.word_embeddings.embedding_dim}\")\n",
    "print(f\"Tamaño del vocabulario del modelo: {model.bert.embeddings.word_embeddings.num_embeddings}\")\n",
    "print(f\"Número de parámetros del modelo: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Número de parámetros entrenables: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detalles del Modelo:\n",
      "---------------------\n",
      "Nombre del Modelo: huawei-noah/TinyBERT_General_4L_312D\n",
      "Parámetros de la capa de embedding: 9683856 (Tipo: Embedding)\n",
      " Esta capa se encarga de convertir los tokens en vectores de embeddings\n",
      "\n",
      "Cantidad de parámetros por capa de codificación:\n",
      "Capa 1 (BertLayer): 1142184 parámetros\n",
      "Capa 2 (BertLayer): 1142184 parámetros\n",
      "Capa 3 (BertLayer): 1142184 parámetros\n",
      "Capa 4 (BertLayer): 1142184 parámetros\n",
      "Procesan las representaciones de los embeddings utilizando self-attention\n",
      "y transformers para capturar relaciones contextuales entre las palabras.\n",
      "\n",
      "Parámetros de la capa de clasificación: 626 (Tipo: Linear)\n",
      "\n",
      "Número total de parámetros del modelo: 14253218\n"
     ]
    }
   ],
   "source": [
    "# Imprimir detalles del modelo\n",
    "print(\"Detalles del Modelo:\")\n",
    "print(\"---------------------\")\n",
    "print(f\"Nombre del Modelo: {model_name}\")\n",
    "\n",
    "# Imprimir parámetros de la capa de embedding\n",
    "embedding_params = sum(p.numel() for p in model.bert.embeddings.parameters())\n",
    "print(f\"Parámetros de la capa de embedding: {embedding_params} (Tipo: Embedding)\")\n",
    "print(\" Esta capa se encarga de convertir los tokens en vectores de embeddings\")\n",
    "# Imprimir la cantidad de parámetros por capa de codificación\n",
    "print(\"\\nCantidad de parámetros por capa de codificación:\")\n",
    "total_encoder_params = 0\n",
    "for i, layer in enumerate(model.bert.encoder.layer):\n",
    "    num_params = sum(p.numel() for p in layer.parameters())\n",
    "    layer_type = layer.__class__.__name__  # Obtener el nombre de la clase\n",
    "    print(f\"Capa {i + 1} ({layer_type}): {num_params} parámetros\")\n",
    "    total_encoder_params += num_params\n",
    "print(\"Procesan las representaciones de los embeddings utilizando self-attention\")\n",
    "print(\"y transformers para capturar relaciones contextuales entre las palabras.\")\n",
    "\n",
    "# Imprimir parámetros de la capa de clasificación\n",
    "classification_params = sum(p.numel() for p in model.classifier.parameters())\n",
    "classification_type = model.classifier.__class__.__name__  # Obtener el nombre de la clase\n",
    "print(f\"\\nParámetros de la capa de clasificación: {classification_params} (Tipo: {classification_type})\")\n",
    "\n",
    "# Número total de parámetros\n",
    "total_params = embedding_params + total_encoder_params + classification_params\n",
    "print(f\"\\nNúmero total de parámetros del modelo: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJEMPLO CON Distilbert pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: I absolutely love this product! It works wonderfully. -> Sentiment: Positive (Class index: 1)\n",
      "Comment: I'm not satisfied with the service; it's too slow. -> Sentiment: Negative (Class index: 0)\n",
      "Comment: Excellent quality; I would recommend it to everyone. -> Sentiment: Positive (Class index: 1)\n",
      "Comment: Terrible experience; I will never buy here again. -> Sentiment: Negative (Class index: 0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Cargar el modelo y el tokenizer preentrenados para análisis de sentimientos\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Función para predecir el sentimiento\n",
    "def predict_sentiment(text):\n",
    "    # Tokenizar el texto de entrada\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Realizar la inferencia\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Obtener la clase predicha\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Interpretar el resultado\n",
    "    sentiment = \"Positive\" if predicted_class == 1 else \"Negative\"\n",
    "    return sentiment, predicted_class\n",
    "\n",
    "# Comentarios de ejemplo para analizar\n",
    "comments = [\n",
    "    \"I absolutely love this product! It works wonderfully.\",\n",
    "    \"I'm not satisfied with the service; it's too slow.\",\n",
    "    \"Excellent quality; I would recommend it to everyone.\",\n",
    "    \"Terrible experience; I will never buy here again.\"\n",
    "]\n",
    "\n",
    "# Analizar el sentimiento de cada comentario\n",
    "for comment in comments:\n",
    "    sentiment, class_index = predict_sentiment(comment)\n",
    "    print(f\"Comment: {comment} -> Sentiment: {sentiment} (Class index: {class_index})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detalles del modelo DistillBERT pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detalles del Modelo:\n",
      "---------------------\n",
      "Capa de Embeddings: 23835648 parámetros (Largo del embedding: 768)\n",
      "Capa 1 (TransformerBlock): 7087872 parámetros\n",
      "Capa 2 (TransformerBlock): 7087872 parámetros\n",
      "Capa 3 (TransformerBlock): 7087872 parámetros\n",
      "Capa 4 (TransformerBlock): 7087872 parámetros\n",
      "Capa 5 (TransformerBlock): 7087872 parámetros\n",
      "Capa 6 (TransformerBlock): 7087872 parámetros\n",
      "Capa de Clasificación: 1538 parámetros (Tipo: Linear)\n",
      "\n",
      "Número total de parámetros del modelo: 66364418\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el tipo y la cantidad de capas del modelo\n",
    "print(\"Detalles del Modelo:\")\n",
    "print(\"---------------------\")\n",
    "\n",
    "# 1. Capas de Embeddings\n",
    "embedding_params = sum(p.numel() for p in model.distilbert.embeddings.parameters())\n",
    "embedding_layer = model.distilbert.embeddings\n",
    "embedding_length = embedding_layer.word_embeddings.weight.shape[1]  # Largo del embedding\n",
    "print(f\"Capa de Embeddings: {embedding_params} parámetros (Largo del embedding: {embedding_length})\")\n",
    "\n",
    "# 2. Capas de Codificación\n",
    "total_encoder_params = 0\n",
    "for i, layer in enumerate(model.distilbert.transformer.layer):\n",
    "    num_params = sum(p.numel() for p in layer.parameters())\n",
    "    layer_type = layer.__class__.__name__\n",
    "    print(f\"Capa {i + 1} ({layer_type}): {num_params} parámetros\")\n",
    "    total_encoder_params += num_params\n",
    "\n",
    "# 3. Capa de Clasificación\n",
    "classification_params = sum(p.numel() for p in model.classifier.parameters())\n",
    "print(f\"Capa de Clasificación: {classification_params} parámetros (Tipo: {model.classifier.__class__.__name__})\")\n",
    "\n",
    "# Número total de parámetros\n",
    "total_params = embedding_params + total_encoder_params + classification_params\n",
    "print(f\"\\nNúmero total de parámetros del modelo: {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
