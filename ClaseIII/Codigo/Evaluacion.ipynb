{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En este ejemplo evaluamos tres modelos distintos pre-entrenados y finetuned de BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at apple/ane-distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- distilbert.transformer.layer.0.attention.q_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.0.attention.k_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.0.attention.v_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.0.attention.out_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.0.ffn.lin1.weight: found shape torch.Size([3072, 768, 1, 1]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.0.ffn.lin2.weight: found shape torch.Size([768, 3072, 1, 1]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated\n",
      "- distilbert.transformer.layer.1.attention.q_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.1.attention.k_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.1.attention.v_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.1.attention.out_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.1.ffn.lin1.weight: found shape torch.Size([3072, 768, 1, 1]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.1.ffn.lin2.weight: found shape torch.Size([768, 3072, 1, 1]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated\n",
      "- distilbert.transformer.layer.2.attention.q_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.2.attention.k_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.2.attention.v_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.2.attention.out_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.2.ffn.lin1.weight: found shape torch.Size([3072, 768, 1, 1]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.2.ffn.lin2.weight: found shape torch.Size([768, 3072, 1, 1]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated\n",
      "- distilbert.transformer.layer.3.attention.q_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.3.attention.k_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.3.attention.v_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.3.attention.out_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.3.ffn.lin1.weight: found shape torch.Size([3072, 768, 1, 1]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.3.ffn.lin2.weight: found shape torch.Size([768, 3072, 1, 1]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated\n",
      "- distilbert.transformer.layer.4.attention.q_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.4.attention.k_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.4.attention.v_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.4.attention.out_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.4.ffn.lin1.weight: found shape torch.Size([3072, 768, 1, 1]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.4.ffn.lin2.weight: found shape torch.Size([768, 3072, 1, 1]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated\n",
      "- distilbert.transformer.layer.5.attention.q_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.5.attention.k_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.5.attention.v_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.5.attention.out_lin.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.5.ffn.lin1.weight: found shape torch.Size([3072, 768, 1, 1]) in the checkpoint and torch.Size([3072, 768]) in the model instantiated\n",
      "- distilbert.transformer.layer.5.ffn.lin2.weight: found shape torch.Size([768, 3072, 1, 1]) in the checkpoint and torch.Size([768, 3072]) in the model instantiated\n",
      "- pre_classifier.weight: found shape torch.Size([768, 768, 1, 1]) in the checkpoint and torch.Size([768, 768]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768, 1, 1]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") predictions [1 1 0 0 0 1 1 0 0 1]\n",
      "model: DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ") predictions [0 0 0 0 0 0 0 0 0 0]\n",
      "model: BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 1024)\n",
      "      (token_type_embeddings): Embedding(2, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ") predictions [1 1 0 1 0 1 1 0 0 1]\n",
      "Modelo 1 (DistilBERT): 9/20 correctos\n",
      "Modelo 2 (ANE DistilBERT): 4/20 correctos\n",
      "Modelo 3 (BERT): 10/20 correctos\n",
      "\n",
      "Ejemplos correctos para Modelo 1 (DistilBERT):\n",
      "Texto: <br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\n",
      "Predicción: 1, Etiqueta: 1\n",
      "\n",
      "Texto: This is the latest entry in the long series of films with the French agent, O.S.S. 117 (the French answer to James Bond). The series was launched in the early 1950's, and spawned at least eight films (none of which was ever released in the U.S.). 'O.S.S.117:Cairo,Nest Of Spies' is a breezy little comedy that should not...repeat NOT, be taken too seriously. Our protagonist finds himself in the middle of a spy chase in Egypt (with Morroco doing stand in for Egypt) to find out about a long lost friend. What follows is the standard James Bond/Inspector Cloussou kind of antics. Although our man is something of an overt xenophobe,sexist,homophobe, it's treated as pure farce (as I said, don't take it too seriously). Although there is a bit of rough language & cartoon violence, it's basically okay for older kids (ages 12 & up). As previously stated in the subject line, just sit back,pass the popcorn & just enjoy.\n",
      "Predicción: 1, Etiqueta: 1\n",
      "\n",
      "Ejemplos incorrectos para Modelo 1 (DistilBERT):\n",
      "Texto: I was truly and wonderfully surprised at \"O' Brother, Where Art Thou?\" The video store was out of all the movies I was planning on renting, so then I came across this. I came home and as I watched I became engrossed and found myself laughing out loud. The Coen's have made a magnificiant film again. But I think the first time you watch this movie, you get to know the characters. The second time, now that you know them, you laugh sooo hard it could hurt you. I strongly would reccomend ANYONE seeing this because if you are not, you are truly missing a film gem for the ages. 10/10\n",
      "Predicción: 0, Etiqueta: 1\n",
      "\n",
      "\n",
      "Ejemplos correctos para Modelo 2 (ANE DistilBERT):\n",
      "Texto: This movie was so frustrating. Everything seemed energetic and I was totally prepared to have a good time. I at least thought I'd be able to stand it. But, I was wrong. First, the weird looping? It was like watching \"America's Funniest Home Videos\". The damn parents. I hated them so much. The stereo-typical Latino family? I need to speak with the person responsible for this. We need to have a talk. That little girl who was always hanging on someone? I just hated her and had to mention it. Now, the final scene transcends, I must say. It's so gloriously bad and full of badness that it is a movie of its own. What crappy dancing. Horrible and beautiful at once.\n",
      "Predicción: 0, Etiqueta: 0\n",
      "\n",
      "Texto: This movie spends most of its time preaching that it is the script that makes the movie, but apparently there was no script when they shot this waste of time! The trailer makes this out to be a comedy, but the film can't decide if it wants to be a comedy, a drama, a romance or an action film. Press releases indicated that Shatner and Hamlin made this movie because they loved the script (what were they thinking?). If you like William Shatner (I do) see \"Free Enterprise\" instead.\n",
      "Predicción: 0, Etiqueta: 0\n",
      "\n",
      "Ejemplos incorrectos para Modelo 2 (ANE DistilBERT):\n",
      "Texto: <br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\n",
      "Predicción: 0, Etiqueta: 1\n",
      "\n",
      "Texto: This is the latest entry in the long series of films with the French agent, O.S.S. 117 (the French answer to James Bond). The series was launched in the early 1950's, and spawned at least eight films (none of which was ever released in the U.S.). 'O.S.S.117:Cairo,Nest Of Spies' is a breezy little comedy that should not...repeat NOT, be taken too seriously. Our protagonist finds himself in the middle of a spy chase in Egypt (with Morroco doing stand in for Egypt) to find out about a long lost friend. What follows is the standard James Bond/Inspector Cloussou kind of antics. Although our man is something of an overt xenophobe,sexist,homophobe, it's treated as pure farce (as I said, don't take it too seriously). Although there is a bit of rough language & cartoon violence, it's basically okay for older kids (ages 12 & up). As previously stated in the subject line, just sit back,pass the popcorn & just enjoy.\n",
      "Predicción: 0, Etiqueta: 1\n",
      "\n",
      "\n",
      "Ejemplos correctos para Modelo 3 (BERT):\n",
      "Texto: <br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\n",
      "Predicción: 1, Etiqueta: 1\n",
      "\n",
      "Texto: This is the latest entry in the long series of films with the French agent, O.S.S. 117 (the French answer to James Bond). The series was launched in the early 1950's, and spawned at least eight films (none of which was ever released in the U.S.). 'O.S.S.117:Cairo,Nest Of Spies' is a breezy little comedy that should not...repeat NOT, be taken too seriously. Our protagonist finds himself in the middle of a spy chase in Egypt (with Morroco doing stand in for Egypt) to find out about a long lost friend. What follows is the standard James Bond/Inspector Cloussou kind of antics. Although our man is something of an overt xenophobe,sexist,homophobe, it's treated as pure farce (as I said, don't take it too seriously). Although there is a bit of rough language & cartoon violence, it's basically okay for older kids (ages 12 & up). As previously stated in the subject line, just sit back,pass the popcorn & just enjoy.\n",
      "Predicción: 1, Etiqueta: 1\n",
      "\n",
      "Ejemplos incorrectos para Modelo 3 (BERT):\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "\n",
    "# Ignorar advertencias\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Cargar el conjunto de datos de SST-2\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Mezclar el conjunto de datos\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "# Cargar los modelos y los tokenizers\n",
    "model1_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model2_name = \"apple/ane-distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model3_name = \"echarlaix/bert-large-uncased-whole-word-masking-finetuned-sst-2\"\n",
    "\n",
    "tokenizer1 = DistilBertTokenizer.from_pretrained(model1_name)\n",
    "tokenizer2 = DistilBertTokenizer.from_pretrained(model2_name)\n",
    "tokenizer3 = BertTokenizer.from_pretrained(model3_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model1 = DistilBertForSequenceClassification.from_pretrained(model1_name, ignore_mismatched_sizes=True).to(device)\n",
    "model2 = DistilBertForSequenceClassification.from_pretrained(model2_name, ignore_mismatched_sizes=True).to(device)\n",
    "model3 = BertForSequenceClassification.from_pretrained(model3_name, ignore_mismatched_sizes=True).to(device)\n",
    "\n",
    "# Función para hacer inferencias\n",
    "def evaluate_model(model, tokenizer, texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = outputs.logits.argmax(dim=-1).cpu().numpy()  # Convertir a numpy\n",
    "    print(\"model:\", model, \"predictions\", predictions)\n",
    "    return predictions\n",
    "\n",
    "# Evaluar los modelos\n",
    "# Evaluate the model on the test set\n",
    "texts = dataset['test']['text'][:10]  # Get the first 100 reviews\n",
    "labels = dataset['test']['label'][:10]  # Corresponding labels\n",
    "\n",
    "predictions1 = evaluate_model(model1, tokenizer1, texts)\n",
    "predictions2 = evaluate_model(model2, tokenizer2, texts)\n",
    "predictions3 = evaluate_model(model3, tokenizer3, texts)\n",
    "\n",
    "# Comparar resultados\n",
    "correct_predictions1 = (predictions1 == labels).sum()\n",
    "correct_predictions2 = (predictions2 == labels).sum()\n",
    "correct_predictions3 = (predictions3 == labels).sum()\n",
    "\n",
    "print(f\"Modelo 1 (DistilBERT): {correct_predictions1}/20 correctos\")\n",
    "print(f\"Modelo 2 (ANE DistilBERT): {correct_predictions2}/20 correctos\")\n",
    "print(f\"Modelo 3 (BERT): {correct_predictions3}/20 correctos\")\n",
    "\n",
    "# Función para imprimir ejemplos correctos e incorrectos\n",
    "def print_examples(predictions, labels, texts, model_name):\n",
    "    correct_indices = [i for i in range(len(predictions)) if predictions[i] == labels[i]]\n",
    "    incorrect_indices = [i for i in range(len(predictions)) if predictions[i] != labels[i]]\n",
    "\n",
    "    print(f\"\\nEjemplos correctos para {model_name}:\")\n",
    "    for idx in correct_indices[:2]:  # Imprimir 2 ejemplos correctos\n",
    "        print(f\"Texto: {texts[idx]}\")\n",
    "        print(f\"Predicción: {predictions[idx]}, Etiqueta: {labels[idx]}\\n\")\n",
    "\n",
    "    print(f\"Ejemplos incorrectos para {model_name}:\")\n",
    "    for idx in incorrect_indices[:2]:  # Imprimir 2 ejemplos incorrectos\n",
    "        print(f\"Texto: {texts[idx]}\")\n",
    "        print(f\"Predicción: {predictions[idx]}, Etiqueta: {labels[idx]}\\n\")\n",
    "\n",
    "# Imprimir ejemplos para todos los modelos\n",
    "print_examples(predictions1, labels, texts, \"Modelo 1 (DistilBERT)\")\n",
    "print_examples(predictions2, labels, texts, \"Modelo 2 (ANE DistilBERT)\")\n",
    "print_examples(predictions3, labels, texts, \"Modelo 3 (BERT)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspeccionamos el dataset GLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n",
      "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0}\n"
     ]
    }
   ],
   "source": [
    "# Importar las bibliotecas\n",
    "from datasets import load_dataset\n",
    "\n",
    "# \"MRPC\" se refiere a Microsoft Research Paraphrase Corpus, \n",
    "# que es uno de los subtareas dentro del conjunto de datos \n",
    "# GLUE (General Language Understanding Evaluation). \n",
    "# MRPC está diseñado para evaluar la capacidad de los modelos de \n",
    "# lenguaje para identificar si dos oraciones son paráfrasis una de la otra.\n",
    "glue_dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "\n",
    "# Ver las características del dataset\n",
    "print(glue_dataset)\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(glue_dataset['train'][0])  # Mostrar el primer ejemplo del conjunto de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n",
      "Ejemplo del conjunto de entrenamiento:\n",
      "{'sentence': 'hide new secretions from the parental units ', 'label': 0, 'idx': 0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311e4804844a4d4cb8b98b3a995e5b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a841b439c7840888720f856bcd8a9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# SST-2, que significa Stanford Sentiment Treebank 2. \n",
    "# Esta tarea se centra en la clasificación de sentimientos \n",
    "sst2_dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# Ver las características del dataset\n",
    "print(sst2_dataset)\n",
    "\n",
    "# Mostrar ejemplos del conjunto de entrenamiento\n",
    "print(\"Ejemplo del conjunto de entrenamiento:\")\n",
    "print(sst2_dataset['train'][0])  # Mostrar el primer ejemplo del conjunto de entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación de CHATGPT 4o-mini en SuperGLUE en la tarea RTE \n",
    "##### evalúa la comprensión del lenguaje natural, determinando si una hipótesis se puede inferir de una premisa dada\n",
    "##### Probar con distintos modelos y con DEBAG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset...\n",
      "Evaluando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:30<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de ejemplos evaluados: 20\n",
      "Ejemplos correctos: 20\n",
      "Ejemplos incorrectos: 0\n",
      "\n",
      "Ejemplos de predicciones incorrectas:\n",
      "\n",
      "Resultados finales:\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Reporte de clasificación:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    entailment       1.00      1.00      1.00        12\n",
      "not_entailment       1.00      1.00      1.00         8\n",
      "\n",
      "      accuracy                           1.00        20\n",
      "     macro avg       1.00      1.00      1.00        20\n",
      "  weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def load_rte_data(split=\"validation\", n_samples=20):\n",
    "    \"\"\"\n",
    "    Carga el dataset RTE de SuperGLUE\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\n",
    "        \"super_glue\", \n",
    "        \"rte\",\n",
    "        trust_remote_code=True\n",
    "    )[split]\n",
    "    \n",
    "    if n_samples:\n",
    "        dataset = dataset.select(range(min(n_samples, len(dataset))))\n",
    "    return dataset\n",
    "\n",
    "def format_prompt(premise, hypothesis):\n",
    "    \"\"\"\n",
    "    Formatea el prompt para la tarea RTE con instrucciones más claras\n",
    "    \"\"\"\n",
    "    return f\"\"\"Dado el siguiente par de oraciones, tu tarea es determinar si la segunda oración (hipótesis) \n",
    "se puede inferir lógicamente de la primera oración (premisa).\n",
    "\n",
    "Premisa: {premise}\n",
    "\n",
    "Hipótesis: {hypothesis}\n",
    "\n",
    "Si la hipótesis se puede inferir lógicamente de la premisa, responde exactamente con la palabra: entailment\n",
    "Si la hipótesis NO se puede inferir lógicamente de la premisa, responde exactamente con la palabra: not_entailment\n",
    "\n",
    "Responde solo con una de estas dos palabras: entailment o not_entailment\n",
    "Respuesta:\"\"\"\n",
    "\n",
    "def get_model_prediction(client, premise, hypothesis, debug=True):\n",
    "    \"\"\"\n",
    "    Obtiene la predicción del modelo usando la API de OpenAI\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\", #\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Eres un asistente experto en lógica y razonamiento. Tu tarea es determinar si una hipótesis se puede inferir lógicamente de una premisa dada.\"},\n",
    "                {\"role\": \"user\", \"content\": format_prompt(premise, hypothesis)}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            max_tokens=10\n",
    "        )\n",
    "        prediction = response.choices[0].message.content.strip().lower()\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\nPremisa: {premise}\")\n",
    "            print(f\"Hipótesis: {hypothesis}\")\n",
    "            print(f\"Predicción raw: {prediction}\")\n",
    "        \n",
    "        # Normalización más estricta de la respuesta\n",
    "        if prediction == 'entailment':\n",
    "            return 'entailment'\n",
    "        elif prediction == 'not_entailment':\n",
    "            return 'not_entailment'\n",
    "        else:\n",
    "            print(f\"⚠️ Respuesta no válida del modelo: {prediction}\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error en la API: {e}\")\n",
    "        time.sleep(20)\n",
    "        return None\n",
    "\n",
    "def evaluate_model(client, dataset, debug=True):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo en el dataset RTE con capacidades de depuración\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    examples_info = []\n",
    "    \n",
    "    # Label map correcto según el dataset de SuperGLUE\n",
    "    label_map = {0: 'entailment', 1: 'not_entailment'}\n",
    "    \n",
    "    for idx, example in enumerate(tqdm(dataset)):\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        true_label = label_map[example['label']]\n",
    "        \n",
    "        pred = get_model_prediction(client, premise, hypothesis, debug=debug)\n",
    "        \n",
    "        if pred is not None:\n",
    "            predictions.append(pred)\n",
    "            true_labels.append(true_label)\n",
    "            \n",
    "            # Guardar información del ejemplo para análisis\n",
    "            examples_info.append({\n",
    "                'idx': idx,\n",
    "                'premise': premise,\n",
    "                'hypothesis': hypothesis,\n",
    "                'true_label': true_label,\n",
    "                'predicted': pred,\n",
    "                'correct': pred == true_label\n",
    "            })\n",
    "            \n",
    "        time.sleep(1)\n",
    "    \n",
    "    return predictions, true_labels, examples_info\n",
    "\n",
    "def analyze_results(examples_info):\n",
    "    \"\"\"\n",
    "    Analiza los resultados de la evaluación en detalle\n",
    "    \"\"\"\n",
    "    correct_examples = [ex for ex in examples_info if ex['correct']]\n",
    "    incorrect_examples = [ex for ex in examples_info if not ex['correct']]\n",
    "    \n",
    "    print(f\"\\nTotal de ejemplos evaluados: {len(examples_info)}\")\n",
    "    print(f\"Ejemplos correctos: {len(correct_examples)}\")\n",
    "    print(f\"Ejemplos incorrectos: {len(incorrect_examples)}\")\n",
    "    \n",
    "    print(\"\\nEjemplos de predicciones incorrectas:\")\n",
    "    for i, example in enumerate(incorrect_examples[:3]):  # Mostrar los primeros 3 errores\n",
    "        print(f\"\\nError {i+1}:\")\n",
    "        print(f\"Premisa: {example['premise']}\")\n",
    "        print(f\"Hipótesis: {example['hypothesis']}\")\n",
    "        print(f\"Etiqueta verdadera: {example['true_label']}\")\n",
    "        print(f\"Predicción: {example['predicted']}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "def main():\n",
    "    # Inicializar cliente de OpenAI\n",
    "    client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "    \n",
    "    # Cargar datos\n",
    "    print(\"Cargando dataset...\")\n",
    "    dataset = load_rte_data(split=\"validation\", n_samples=20)  # Reducir muestras para depuración\n",
    "    \n",
    "    # Evaluar modelo\n",
    "    print(\"Evaluando modelo...\")\n",
    "    predictions, true_labels, examples_info = evaluate_model(client, dataset, debug=False)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    report = classification_report(true_labels, predictions)\n",
    "    \n",
    "    # Analizar resultados\n",
    "    analyze_results(examples_info)\n",
    "    \n",
    "    # Guardar resultados detallados\n",
    "    results = {\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"classification_report\": report,\n",
    "        \"examples_info\": examples_info\n",
    "    }\n",
    "    \n",
    "    with open(\"evaluation_results_detailed.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(\"\\nResultados finales:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nReporte de clasificación:\")\n",
    "    print(report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
