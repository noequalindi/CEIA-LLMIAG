{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de IMDB (clasificación de sentimientos)\n",
    "dataset = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizamos el texto: BERT requiere que el texto sea tokenizado de manera específica, por lo que utilizaremos el tokenizador de BERT para convertir las frases en secuencias de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el tokenizador BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Función para tokenizar los datos\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# Aplicar el tokenizador a todo el dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y evaluación\n",
    "train_dataset = tokenized_datasets['train']\n",
    "test_dataset = tokenized_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo BERT preentrenado para clasificación\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuramos los parámetros de entrenamiento: Vamos a configurar los parámetros de entrenamiento utilizando TrainingArguments para el Trainer de Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # directorio donde se guardan los resultados\n",
    "    num_train_epochs=3,              # número de épocas de entrenamiento\n",
    "    per_device_train_batch_size=8,   # tamaño del batch para el entrenamiento\n",
    "    per_device_eval_batch_size=8,    # tamaño del batch para la evaluación\n",
    "    warmup_steps=500,                # número de pasos de warmup\n",
    "    weight_decay=0.01,               # regularización L2\n",
    "    logging_dir='./logs',            # directorio de logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",     # Evaluar al final de cada época\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definimos las métricas de evaluación: Vamos a definir una función para evaluar el modelo en base a la precisión (accuracy) para ver cómo está funcionando durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    return accuracy_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creamos el objeto Trainer: Usamos el Trainer de Hugging Face, que es una forma muy fácil de entrenar el modelo con un conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # El modelo a entrenar\n",
    "    args=training_args,                  # Los parámetros de entrenamiento\n",
    "    train_dataset=train_dataset,         # Dataset de entrenamiento\n",
    "    eval_dataset=test_dataset,           # Dataset de evaluación\n",
    "    compute_metrics=compute_metrics      # Función para computar las métricas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo !!!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el modelo en el conjunto de test\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo entrenado\n",
    "model.save_pretrained('./bert_finetuned')\n",
    "tokenizer.save_pretrained('./bert_finetuned')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
